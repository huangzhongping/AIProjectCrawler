#!/usr/bin/env python3
"""
AIçˆ†æ¬¾é¡¹ç›®é›·è¾¾ - ä¸»ç¨‹åºå…¥å£
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

from utils.logger import setup_logger
from utils.config import load_config
from crawlers.github_crawler import GitHubCrawler
from crawlers.producthunt_crawler import ProductHuntCrawler
from ai_analysis.classifier import AIProjectClassifier
from ai_analysis.keyword_extractor import KeywordExtractor
from ai_analysis.summarizer import ProjectSummarizer
from utils.data_cleaner import DataCleaner
from utils.storage import DataStorage
from utils.daily_records import DailyRecordsManager
from visualization.report_generator import ReportGenerator
from visualization.chart_generator import ChartGenerator
from visualization.history_generator import HistoryPageGenerator


class AITrendingRadar:
    """AIçˆ†æ¬¾é¡¹ç›®é›·è¾¾ä¸»ç±»"""
    
    def __init__(self, config_path=None):
        """åˆå§‹åŒ–"""
        self.config = load_config(config_path)
        self.logger = setup_logger()
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.github_crawler = GitHubCrawler(self.config)
        self.producthunt_crawler = ProductHuntCrawler(self.config)
        self.ai_classifier = AIProjectClassifier(self.config)
        self.keyword_extractor = KeywordExtractor(self.config)
        self.summarizer = ProjectSummarizer(self.config)
        self.data_cleaner = DataCleaner(self.config)
        self.storage = DataStorage(self.config)
        self.daily_records = DailyRecordsManager(self.config)
        self.report_generator = ReportGenerator(self.config)
        self.chart_generator = ChartGenerator(self.config)
        self.history_generator = HistoryPageGenerator(self.config)
    
    async def run_daily_update(self):
        """æ‰§è¡Œæ¯æ—¥æ›´æ–°æµç¨‹"""
        self.logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥AIé¡¹ç›®é›·è¾¾æ›´æ–°...")
        
        try:
            # 1. æ•°æ®æŠ“å–
            self.logger.info("æ­¥éª¤1: å¼€å§‹æ•°æ®æŠ“å–...")
            github_data = await self.github_crawler.crawl()
            producthunt_data = await self.producthunt_crawler.crawl()
            
            # 2. æ•°æ®åˆå¹¶å’Œæ¸…æ´—
            self.logger.info("æ­¥éª¤2: æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–...")
            raw_data = github_data + producthunt_data
            cleaned_data = self.data_cleaner.clean_and_deduplicate(raw_data)
            
            # 3. AIåˆ†æ
            self.logger.info("æ­¥éª¤3: AIé¡¹ç›®åˆ†æ...")
            ai_projects = []
            for project in cleaned_data:
                # AIç›¸å…³æ€§åˆ¤æ–­
                classification = await self.ai_classifier.classify(project)
                if classification['is_ai_related']:
                    # å…³é”®è¯æå–
                    keywords = await self.keyword_extractor.extract(project)
                    # é¡¹ç›®æ€»ç»“
                    summary = await self.summarizer.summarize(project)
                    
                    project.update({
                        'ai_classification': classification,
                        'keywords': keywords,
                        'summary': summary
                    })
                    ai_projects.append(project)
            
            # 4. æ•°æ®å­˜å‚¨
            self.logger.info("æ­¥éª¤4: æ•°æ®å­˜å‚¨...")
            today = datetime.now().strftime("%Y-%m-%d")
            self.storage.save_daily_data(ai_projects, today)
            
            # 5. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
            self.logger.info("æ­¥éª¤5: ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š...")
            # ç”Ÿæˆå›¾è¡¨
            charts = self.chart_generator.generate_daily_charts(ai_projects)
            # ç”ŸæˆæŠ¥å‘Š
            report = await self.report_generator.generate_daily_report(ai_projects, charts)
            
            # 6. ä¿å­˜è¾“å‡ºæ–‡ä»¶
            self.logger.info("æ­¥éª¤6: ä¿å­˜è¾“å‡ºæ–‡ä»¶...")
            output_dir = Path(self.config['data']['paths']['output'])
            
            # ä¿å­˜HTMLæŠ¥å‘Š
            html_path = output_dir / "reports" / f"ai-trends-{today}.html"
            html_path.parent.mkdir(parents=True, exist_ok=True)
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(report['html'])
            
            # ä¿å­˜MarkdownæŠ¥å‘Š
            md_path = output_dir / "reports" / f"ai-trends-{today}.md"
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(report['markdown'])
            
            # æ›´æ–°æœ€æ–°æŠ¥å‘Šé“¾æ¥
            latest_html = output_dir / "web" / "index.html"
            latest_html.parent.mkdir(parents=True, exist_ok=True)
            with open(latest_html, 'w', encoding='utf-8') as f:
                f.write(report['html'])

            # ä¿å­˜æ¯æ—¥è®°å½•
            self.logger.info("æ­¥éª¤6: ä¿å­˜æ¯æ—¥è®°å½•...")
            self.daily_records.save_daily_record(today, cleaned_data, ai_projects)

            # ç”Ÿæˆå†å²è®°å½•é¡µé¢
            self.logger.info("æ­¥éª¤7: ç”Ÿæˆå†å²è®°å½•é¡µé¢...")
            history_path = self.history_generator.generate_history_page()

            self.logger.info(f"âœ… æ¯æ—¥æ›´æ–°å®Œæˆï¼å‘ç° {len(ai_projects)} ä¸ªAIç›¸å…³é¡¹ç›®")
            self.logger.info(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜åˆ°: {html_path}")
            self.logger.info(f"ğŸ“š å†å²è®°å½•é¡µé¢: {history_path}")
            
            return {
                'success': True,
                'ai_projects_count': len(ai_projects),
                'total_projects_count': len(cleaned_data),
                'report_path': str(html_path)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ æ¯æ—¥æ›´æ–°å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    async def run_analysis_only(self, data_file: str):
        """ä»…è¿è¡ŒAIåˆ†æï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        self.logger.info(f"å¼€å§‹åˆ†ææ•°æ®æ–‡ä»¶: {data_file}")
        
        try:
            # åŠ è½½æ•°æ®
            data = self.storage.load_data(data_file)
            
            # AIåˆ†æ
            ai_projects = []
            for project in data:
                classification = await self.ai_classifier.classify(project)
                if classification['is_ai_related']:
                    keywords = await self.keyword_extractor.extract(project)
                    summary = await self.summarizer.summarize(project)
                    
                    project.update({
                        'ai_classification': classification,
                        'keywords': keywords,
                        'summary': summary
                    })
                    ai_projects.append(project)
            
            self.logger.info(f"âœ… åˆ†æå®Œæˆï¼å‘ç° {len(ai_projects)} ä¸ªAIç›¸å…³é¡¹ç›®")
            return ai_projects
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
            raise


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AIçˆ†æ¬¾é¡¹ç›®é›·è¾¾")
    parser.add_argument("--mode", choices=["daily", "analysis"], default="daily",
                       help="è¿è¡Œæ¨¡å¼: daily=æ¯æ—¥æ›´æ–°, analysis=ä»…åˆ†æ")
    parser.add_argument("--data-file", help="åˆ†ææ¨¡å¼ä¸‹çš„æ•°æ®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    radar = AITrendingRadar()
    
    if args.mode == "daily":
        result = await radar.run_daily_update()
        if result['success']:
            print(f"âœ… æ¯æ—¥æ›´æ–°æˆåŠŸï¼å‘ç° {result['ai_projects_count']} ä¸ªAIé¡¹ç›®")
            print(f"ğŸ“Š æŠ¥å‘Šè·¯å¾„: {result['report_path']}")
        else:
            print(f"âŒ æ›´æ–°å¤±è´¥: {result['error']}")
            sys.exit(1)
    
    elif args.mode == "analysis":
        if not args.data_file:
            print("âŒ åˆ†ææ¨¡å¼éœ€è¦æŒ‡å®š --data-file å‚æ•°")
            sys.exit(1)
        
        ai_projects = await radar.run_analysis_only(args.data_file)
        print(f"âœ… åˆ†æå®Œæˆï¼å‘ç° {len(ai_projects)} ä¸ªAIé¡¹ç›®")


if __name__ == "__main__":
    asyncio.run(main())
